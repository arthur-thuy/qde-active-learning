{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import re\n",
    "\n",
    "# related third party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local application/library specific imports\n",
    "from tools.configurator import (\n",
    "    get_configs_out,\n",
    "    get_config_ids,\n",
    ")\n",
    "from tools.analyzer import (\n",
    "    get_labelling_progress,\n",
    "    Dict2Class,\n",
    "    get_train_logs,\n",
    "    find_label_map,\n",
    "    get_single_pred_label,\n",
    "    merge_all_results,\n",
    ")\n",
    "from tools.plotter import (\n",
    "    plot_level_acquisitions,\n",
    "    plot_level_performance,\n",
    "    plot_metric_vs_size,\n",
    "    plot_active_gain,\n",
    "    plot_history,\n",
    "    plot_violinplot_racepp,\n",
    "    plot_pred_parity,\n",
    ")\n",
    "from data_loader.build import build_hf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "exp_name = \"race_pp_merged\"\n",
    "metric = \"test_discrete_rmse\"\n",
    "SANS_SERIF = True\n",
    "PRINT_PAPER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_latex(sans_serif: bool = False):\n",
    "    \"\"\"Activate latex for matplotlib.\"\"\"\n",
    "    if sans_serif:\n",
    "        plt.rcParams.update(\n",
    "            {\n",
    "                \"text.usetex\": True,\n",
    "                \"font.family\": \"Helvetica\",\n",
    "                \"text.latex.preamble\": r\"\\usepackage[cm]{sfmath}\",\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        plt.rcParams.update(\n",
    "            {\"text.usetex\": True, \"font.family\": \"Computer Modern Roman\"}\n",
    "        )\n",
    "\n",
    "\n",
    "def deactivate_latex():\n",
    "    \"\"\"Deactivate latex for matplotlib.\"\"\"\n",
    "    plt.rcParams.update(\n",
    "        {\"text.usetex\": False, \"font.family\": \"DejaVu Sans\", \"text.latex.preamble\": \"\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC2LEGEND_DICT = {\n",
    "    \"test_discrete_rmse\": \"Discrete RMSE\",\n",
    "    \"test_rmse\": \"RMSE\",\n",
    "}\n",
    "\n",
    "CONFIG2LEGEND_DICT = {\n",
    "    \"distilbert-base-uncased-regr-full_data\": \"Baseline - Supervised\",\n",
    "    \"random-regr-full_data\": \"Baseline - Random\",\n",
    "    \"majority-regr-full_data\": \"Baseline - Majority\",\n",
    "    \"distilbert-base-uncased-regr-random-STD-N96-Q100-I500-S5000-BFalse\": \"AL - Uniform\",\n",
    "    \"distilbert-base-uncased-regr-powervariance-MCD-N96-Q100-I500-S5000-BFalse\": \"AL - PowerVariance\",\n",
    "    \"distilbert-base-uncased-regr-variance-MCD-N96-Q100-I500-S5000-BFalse\": \"AL - Variance\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_configs_out(exp_name)\n",
    "config_ids = get_config_ids(configs)\n",
    "print(config_ids)\n",
    "\n",
    "config_dict = {config_id: cfg for config_id, cfg in zip(config_ids, configs)}\n",
    "# e.g. do `config_dict[\"powerbald-MC_dropout\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge results for all configs\n",
    "merge_all_results(exp_name, config_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # automatic\n",
    "# baselines = [\"random-regr-full_data\", \"majority-regr-full_data\"]\n",
    "# CONFIG_IDS_TO_PLOT = [x for x in config_ids if x not in baselines]\n",
    "# CONFIG_IDS_AL = [x for x in config_ids if \"full_data\" not in x]\n",
    "\n",
    "# manual\n",
    "CONFIG_IDS_AL = [\n",
    "    \"distilbert-base-uncased-regr-random-STD-N96-Q100-I500-S5000-BFalse\",\n",
    "    \"distilbert-base-uncased-regr-variance-MCD-N96-Q100-I500-S5000-BFalse\",\n",
    "    \"distilbert-base-uncased-regr-powervariance-MCD-N96-Q100-I500-S5000-BFalse\",\n",
    "]\n",
    "CONFIG_IDS_TO_PLOT = CONFIG_IDS_AL + [\"distilbert-base-uncased-regr-full_data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric vs dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric_vs_size(\n",
    "#     exp_name=exp_name,\n",
    "#     metric=metric,\n",
    "#     config_ids=config_ids,\n",
    "#     run_id=None,\n",
    "#     config2legend=CONFIG2LEGEND_DICT,\n",
    "#     metric2legend=METRIC2LEGEND_DICT,\n",
    "#     stderr=False,  # True,\n",
    "#     x_axis=\"percent\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_vs_size(\n",
    "    exp_name=exp_name,\n",
    "    metric=metric,\n",
    "    config_ids=CONFIG_IDS_TO_PLOT,\n",
    "    run_id=None,\n",
    "    config2legend=CONFIG2LEGEND_DICT,\n",
    "    metric2legend=METRIC2LEGEND_DICT,\n",
    "    stderr=False,  # True,\n",
    "    x_axis=\"percent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRINT_PAPER:\n",
    "    activate_latex(sans_serif=SANS_SERIF)\n",
    "    ########\n",
    "    savefig_kwargs = {\n",
    "        \"fname\": os.path.join(\"output\", exp_name, \"figures\", f\"{metric}_vs_size.pdf\")\n",
    "    }\n",
    "    plot_metric_vs_size(\n",
    "        exp_name=exp_name,\n",
    "        metric=metric,\n",
    "        config_ids=CONFIG_IDS_TO_PLOT,\n",
    "        run_id=None,\n",
    "        config2legend=CONFIG2LEGEND_DICT,\n",
    "        metric2legend=METRIC2LEGEND_DICT,\n",
    "        stderr=False,  # True,\n",
    "        x_axis=\"percent\",\n",
    "        save=True,\n",
    "        savefig_kwargs=savefig_kwargs,\n",
    "    )\n",
    "    ########\n",
    "    savefig_kwargs = {\n",
    "        \"fname\": os.path.join(\"output\", exp_name, \"figures\", f\"{metric}_vs_size_stderr.pdf\")\n",
    "    }\n",
    "    plot_metric_vs_size(\n",
    "        exp_name=exp_name,\n",
    "        metric=metric,\n",
    "        config_ids=CONFIG_IDS_TO_PLOT,\n",
    "        run_id=None,\n",
    "        config2legend=CONFIG2LEGEND_DICT,\n",
    "        metric2legend=METRIC2LEGEND_DICT,\n",
    "        stderr=True,\n",
    "        x_axis=\"percent\",\n",
    "        save=True,\n",
    "        savefig_kwargs=savefig_kwargs,\n",
    "    )\n",
    "    ########\n",
    "    deactivate_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "config_id = \"distilbert-base-uncased-regr-powervariance-MCD-N96-Q100-I500-S5000-BFalse\"\n",
    "run_id = 1\n",
    "ds_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log, lines, eval_results = get_train_logs(\n",
    "    exp_name=exp_name, config_id=config_id, run_id=run_id, ds_size=ds_size\n",
    ")\n",
    "plot_history(lines, \"eval_rmse\")\n",
    "plot_history(lines, \"eval_discrete_rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "# config_id = USE FROM ABOVE\n",
    "run_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling progress\n",
    "labelling_dict = get_labelling_progress(exp_name, config_ids)\n",
    "\n",
    "# NOTE: no random process in dataset building so seed does not matter\n",
    "datasets_runs = {}\n",
    "for run_key, run_value in labelling_dict[config_id].items():\n",
    "    run_n = int(re.search(r\"run_(\\d+)\", run_key).group(1))\n",
    "    datasets_runs[run_key] = build_hf_dataset(\n",
    "        Dict2Class(config_dict[config_id][\"LOADER\"]),\n",
    "        config_dict[config_id][\"MODEL\"][\"NUM_LABELS\"],\n",
    "        config_dict[config_id][\"SEED\"] + run_n,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of all labeled samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: label map is same for all dataset seeds\n",
    "label_map = find_label_map(datasets_runs[\"run_1\"][\"train\"])\n",
    "plot_level_acquisitions(\n",
    "    labelling_dict=labelling_dict,\n",
    "    datasets=datasets_runs,\n",
    "    label_map=label_map,\n",
    "    config_dict=config_dict,\n",
    "    config_id=config_id,\n",
    "    exp_name=exp_name,\n",
    "    run_id=run_id,\n",
    "    x_axis=\"percent\",\n",
    "    only_acquisition=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all AL configs (over all runs)\n",
    "if PRINT_PAPER:\n",
    "    activate_latex(sans_serif=SANS_SERIF)\n",
    "\n",
    "    for config_id_tmp in CONFIG_IDS_AL:\n",
    "        savefig_kwargs = {\n",
    "            \"fname\": os.path.join(\n",
    "                \"output\", exp_name, \"figures\", f\"labeling_progress_{config_id_tmp}.pdf\"\n",
    "            )\n",
    "        }\n",
    "        plot_level_acquisitions(\n",
    "            labelling_dict=labelling_dict,\n",
    "            datasets=datasets_runs,\n",
    "            label_map=label_map,\n",
    "            config_dict=config_dict,\n",
    "            config_id=config_id_tmp,\n",
    "            exp_name=exp_name,\n",
    "            run_id=None,\n",
    "            x_axis=\"percent\",\n",
    "            only_acquisition=False,\n",
    "            save=True,\n",
    "            savefig_kwargs=savefig_kwargs,\n",
    "        )\n",
    "    ########\n",
    "    deactivate_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of samples acquired per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_level_acquisitions(\n",
    "    labelling_dict=labelling_dict,\n",
    "    datasets=datasets_runs,\n",
    "    label_map=label_map,\n",
    "    config_dict=config_dict,\n",
    "    config_id=config_id,\n",
    "    exp_name=exp_name,\n",
    "    run_id=run_id,\n",
    "    x_axis=\"percent\",\n",
    "    only_acquisition=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics per difficulty level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "# config_id = USE FROM ABOVE\n",
    "diff_level = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric for 1 difficulty level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_level_performance(\n",
    "    experiment=exp_name,\n",
    "    metric=metric,\n",
    "    config_ids=[config_id],\n",
    "    config_dict=config_dict,\n",
    "    label_map=label_map,\n",
    "    diff_level=diff_level,\n",
    "    run_id=None,\n",
    "    x_axis=\"percent\",\n",
    "    config2legend=CONFIG2LEGEND_DICT,\n",
    "    metric2legend=METRIC2LEGEND_DICT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all AL configs\n",
    "if PRINT_PAPER:\n",
    "    activate_latex(sans_serif=SANS_SERIF)\n",
    "\n",
    "    for label_str in label_map.values():\n",
    "        savefig_kwargs = {\n",
    "            \"fname\": os.path.join(\n",
    "                \"output\", exp_name, \"figures\", f\"difficulty_level_{label_str}.pdf\"\n",
    "            )\n",
    "        }\n",
    "        plot_level_performance(\n",
    "            experiment=exp_name,\n",
    "            metric=metric,\n",
    "            config_ids=CONFIG_IDS_AL,\n",
    "            config_dict=config_dict,\n",
    "            label_map=label_map,\n",
    "            diff_level=label_str,\n",
    "            run_id=None,\n",
    "            x_axis=\"percent\",\n",
    "            config2legend=CONFIG2LEGEND_DICT,\n",
    "            metric2legend=METRIC2LEGEND_DICT,\n",
    "            save=True,\n",
    "            savefig_kwargs=savefig_kwargs,\n",
    "        )\n",
    "\n",
    "    ########\n",
    "    deactivate_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric for all difficulty levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_level_performance(\n",
    "    experiment=exp_name,\n",
    "    metric=metric,\n",
    "    config_ids=[config_id],\n",
    "    config_dict=config_dict,\n",
    "    label_map=label_map,\n",
    "    diff_level=None,\n",
    "    run_id=None,\n",
    "    x_axis=\"percent\",\n",
    "    config2legend=CONFIG2LEGEND_DICT,\n",
    "    metric2legend=METRIC2LEGEND_DICT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_parity(\n",
    "    experiment=exp_name,\n",
    "    metric=metric,\n",
    "    config_ids=CONFIG_IDS_AL,  # [config_id],\n",
    "    config_dict=config_dict,\n",
    "    label_map=label_map,\n",
    "    run_id=run_id,\n",
    "    x_axis=\"percent\",\n",
    "    stderr=False,\n",
    "    config2legend=CONFIG2LEGEND_DICT,\n",
    "    metric2legend=METRIC2LEGEND_DICT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin plots of difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "# config_id = USE FROM ABOVE\n",
    "run_id = 3\n",
    "ds_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_label = get_single_pred_label(exp_name, config_id, run_id, ds_size)\n",
    "plot_violinplot_racepp(test_pred_label, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all AL configs\n",
    "if PRINT_PAPER:\n",
    "    activate_latex(sans_serif=SANS_SERIF)\n",
    "\n",
    "    for config_id_tmp in CONFIG_IDS_AL:\n",
    "        savefig_kwargs = {\n",
    "            \"fname\": os.path.join(\n",
    "                \"output\", exp_name, \"figures\", f\"violin_plot_{config_id_tmp}.pdf\"\n",
    "            )\n",
    "        }\n",
    "        test_pred_label = get_single_pred_label(exp_name, config_id_tmp, run_id, ds_size)\n",
    "        plot_violinplot_racepp(test_pred_label, label_map, save=True, savefig_kwargs=savefig_kwargs)\n",
    "    ########\n",
    "    deactivate_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "baseline = \"distilbert-base-uncased-regr-random-STD-N96-Q100-I500-S5000-BFalse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_active_gain(\n",
    "    exp_name=exp_name,\n",
    "    metric=metric,\n",
    "    baseline=baseline,\n",
    "    config_ids=CONFIG_IDS_AL,\n",
    "    run_id=None,\n",
    "    config2legend=CONFIG2LEGEND_DICT,\n",
    "    metric2legend=METRIC2LEGEND_DICT,\n",
    "    x_axis=\"percent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRINT_PAPER:\n",
    "    activate_latex(sans_serif=SANS_SERIF)\n",
    "    ########\n",
    "    savefig_kwargs = {\n",
    "        \"fname\": os.path.join(\n",
    "            \"output\", exp_name, \"figures\", f\"{metric}_active_gain.pdf\"\n",
    "        )\n",
    "    }\n",
    "    plot_active_gain(\n",
    "        exp_name=exp_name,\n",
    "        metric=metric,\n",
    "        baseline=baseline,\n",
    "        config_ids=CONFIG_IDS_AL,\n",
    "        run_id=None,\n",
    "        config2legend=CONFIG2LEGEND_DICT,\n",
    "        metric2legend=METRIC2LEGEND_DICT,\n",
    "        x_axis=\"percent\",\n",
    "        save=True,\n",
    "        savefig_kwargs=savefig_kwargs,\n",
    "    )\n",
    "    ########\n",
    "    deactivate_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
